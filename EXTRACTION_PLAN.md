# Sneaker: Clean Extraction from Ghost

**Date:** November 12, 2025
**Purpose:** Extract only the working core from Ghost, leave behind the mess

---

## Philosophy: Start Fresh

Ghost has become a tangled mess of:
- 94+ issues worth of experiments
- Failed approaches (voting ensembles, censored models, etc.)
- V1/V2 buggy models
- Complex infrastructure that's not being used
- Confusing documentation

**Sneaker will be:**
- Clean, simple, working code only
- One approach: V3 sample weighting
- Clear documentation
- No historical baggage

---

## What to Extract (The Good Hair)

### 1. Core Ghost Signal Detection
**From:** `test/detect_ghost_signals_volnorm.py`
**What it does:** Detects indicator momentum shifts (ghost signals)
**Why:** This is the core innovation that works

### 2. Feature Engineering (83 Enhanced V3 Features)
**From:**
- `test/add_momentum_features.py` (Batch 1: 24 features)
- `test/add_even_more_features.py` (Batch 2: 35 features)
- `test/add_issue70_statistical_features.py` (Batch 3: 4 features)
**What it does:** Adds 83 technical features to raw candles
**Why:** These features give the model predictive power

### 3. V3 Training Pipeline
**From:** `scripts/train_production_model_v3.py`
**What it does:** Trains LightGBM with 5x sample weighting for signals
**Why:** This is the ONLY approach that works (5% signal rate at 4Ïƒ)

### 4. Data Collection
**From:**
- `scripts/download_1h_data.py` (Binance 1H candles)
- `ghost/data/binance_client.py` (API wrapper)
**What it does:** Fetches historical data from Binance
**Why:** Need data to train and test

### 5. Essential Utilities
**From:**
- `ghost/logging/logger.py` (Logging setup)
- Basic indicator calculations from `ghost/features/indicators.py`
**What it does:** Infrastructure for logging and calculations
**Why:** Basic necessities

### 6. Working Model
**From:** `models/production_model_v3.txt`
**What it does:** The trained V3 model (Signal RÂ² 74%, 5% signal rate)
**Why:** The end product that actually works

### 7. Dataset
**From:** `data_artifacts/ghost_signals_volnorm_enhanced_v3_all_pairs.json`
**What it does:** 917K candles with 83 features and ghost signal targets
**Why:** The training data

---

## What to Leave Behind (The Bad Haircut)

### 1. Failed Experiments
- âŒ All archived scripts (voting ensembles, sign/magnitude split, etc.)
- âŒ V1 and V2 models (buggy/unusable)
- âŒ Censored, quantile, Huber models (have V1 bug)
- âŒ All the training logs and experimental results

### 2. Unused Infrastructure
- âŒ Chopper classes (not used in V3)
- âŒ Dual offset aggregation (not used)
- âŒ Cross-exchange features (not used)
- âŒ Futures data (not used in V3)
- âŒ Macro indicators (not used in V3)
- âŒ Complex evaluation frameworks (not used)

### 3. Confusing Documentation
- âŒ CLAUDE.md with 94 issues of history
- âŒ Multiple experimental summaries
- âŒ V1/V2 comparison docs
- âŒ All the issue tracking

### 4. Development Cruft
- âŒ .venv directories
- âŒ __pycache__
- âŒ .DS_Store files
- âŒ Old log files
- âŒ Test notebooks

---

## Clean Sneaker Structure

```
sneaker/
â”œâ”€â”€ README.md                          # Fresh, simple documentation
â”œâ”€â”€ requirements.txt                   # Minimal dependencies
â”œâ”€â”€ setup.py                           # Package installation
â”‚
â”œâ”€â”€ sneaker/                           # Core module (renamed from ghost)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ indicators.py                  # Technical indicator calculations
â”‚   â”œâ”€â”€ signals.py                     # Ghost signal detection (volnorm)
â”‚   â”œâ”€â”€ features.py                    # 83 Enhanced V3 features
â”‚   â”œâ”€â”€ data.py                        # Binance data fetching
â”‚   â”œâ”€â”€ model.py                       # Model training and prediction
â”‚   â””â”€â”€ logging.py                     # Logging utilities
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ 01_collect_data.py             # Step 1: Fetch Binance data
â”‚   â”œâ”€â”€ 02_detect_signals.py           # Step 2: Find ghost signals
â”‚   â”œâ”€â”€ 03_add_features.py             # Step 3: Add 83 features
â”‚   â”œâ”€â”€ 04_train_model.py              # Step 4: Train V3 model
â”‚   â””â”€â”€ 05_predict.py                  # Step 5: Make predictions
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ production.txt                 # V3 trained model
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ .gitkeep                       # Data goes here
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ test_indicators.py
    â”œâ”€â”€ test_signals.py
    â”œâ”€â”€ test_features.py
    â””â”€â”€ test_model.py
```

---

## Simplified Pipeline

**Ghost had:** 8+ experimental approaches, complex infrastructure, 94 issues of cruft

**Sneaker will have:** One clean pipeline that works

```
1. Collect Data â†’ Binance 1H candles (20 pairs)
2. Detect Signals â†’ Find indicator momentum shifts (volnorm)
3. Add Features â†’ 83 Enhanced V3 features
4. Train Model â†’ LightGBM with 5x sample weighting
5. Predict â†’ Apply model, use 4Ïƒ threshold
```

That's it. Simple. Clean. Working.

---

## Key Simplifications

### Ghost Complexity â†’ Sneaker Simplicity

| Ghost | Sneaker |
|-------|---------|
| 3 buggy model versions (V1/V2/V3) | 1 working model (V3 only) |
| Multiple training approaches | 1 approach: sample weighting |
| Complex chopper/dual-offset classes | Simple functions |
| Futures/macro data (unused) | Only what's used |
| 94 issues of history | Fresh start |
| Confusing docs | Clear README |
| Multiple experimental features | 83 working features |

### Dependencies: Minimal

```
numpy
pandas
lightgbm
binance-client
matplotlib  # for visualizations
scipy       # for statistical features
```

That's it. No xgboost, no sklearn ensemble, no complex frameworks.

---

## Implementation Steps

1. **Create Structure** âœ…
   - Set up clean directory tree
   - Initialize git repo
   - Create venv

2. **Extract Core Code**
   - Copy and clean indicator calculations
   - Extract ghost signal detection (volnorm)
   - Consolidate feature engineering into one module
   - Simplify data collection
   - Extract V3 training logic

3. **Write Fresh Documentation**
   - Simple README explaining what it does
   - How to use (5 simple steps)
   - No historical baggage

4. **Test**
   - Verify each step works independently
   - Run end-to-end pipeline
   - Validate model predictions

5. **Clean Up**
   - Remove any cruft
   - Ensure code is readable
   - Add docstrings

---

## Success Criteria

Sneaker will be considered successful when:
- [ ] Can fetch data with one command
- [ ] Can detect ghost signals with one command
- [ ] Can add all 83 features with one command
- [ ] Can train V3 model with one command
- [ ] Can make predictions with one command
- [ ] Model generates 5% signals at 4Ïƒ (like V3)
- [ ] Code is clean, readable, and documented
- [ ] No historical Ghost baggage

---

## Guiding Principles

1. **KISS:** Keep It Simple, Stupid
2. **One Way:** Only include what works (V3)
3. **No History:** Fresh start, no baggage
4. **Readable:** Code that makes sense 6 months from now
5. **Working:** Every part tested and functional

---

## Next Actions

1. Create sneaker directory structure
2. Extract and clean core modules
3. Copy V3 model and dataset
4. Write fresh README
5. Test end-to-end
6. Celebrate clean codebase ğŸ‰
